#!/usr/bin/env python3
"""
æµ‹è¯•RSSå›¾ç‰‡ä¸‹è½½åŠŸèƒ½
"""

import sys
import os
# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.services.rss_service import RSSFetcher
from src.services.image_service import ImageDownloader

def test_image_download():
    """æµ‹è¯•å›¾ç‰‡ä¸‹è½½åŠŸèƒ½"""
    
    print("ğŸ” æµ‹è¯•RSSå›¾ç‰‡ä¸‹è½½åŠŸèƒ½...")
    print("=" * 60)
    
    # æµ‹è¯•å›¾ç‰‡ä¸‹è½½å™¨
    print("ğŸ“¥ æµ‹è¯•å›¾ç‰‡ä¸‹è½½å™¨...")
    image_downloader = ImageDownloader()
    
    # æµ‹è¯•ç¤ºä¾‹å›¾ç‰‡URL
    test_image_url = "https://techcrunch.com/wp-content/uploads/2024/01/openai-logo.jpg"
    
    print(f"æµ‹è¯•å›¾ç‰‡URL: {test_image_url}")
    print(f"å›¾ç‰‡æ ¼å¼æ£€æŸ¥: {image_downloader._is_valid_image_url(test_image_url)}")
    
    # æµ‹è¯•å†…å®¹è§£æ
    test_html = '''
    <div>
        <p>è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡ç« </p>
        <img src="https://example.com/test-image.jpg" alt="æµ‹è¯•å›¾ç‰‡">
        <p>æ›´å¤šå†…å®¹</p>
    </div>
    '''
    
    extracted_url = image_downloader.extract_image_from_content(test_html, "https://example.com")
    print(f"ä»HTMLæå–çš„å›¾ç‰‡URL: {extracted_url}")
    
    # æµ‹è¯•RSSè·å–å™¨
    print("\nğŸ“° æµ‹è¯•RSSå›¾ç‰‡è·å–...")
    
    try:
        rss_fetcher = RSSFetcher()
        print(f"RSSæº: {rss_fetcher.feed_url}")
        
        # è·å–æœ€æ–°æ–‡ç« ï¼ˆå¯ç”¨å›¾ç‰‡ä¸‹è½½ï¼‰
        print("æ­£åœ¨è·å–RSSæ–‡ç« ...")
        # ä¸´æ—¶ä¿®æ”¹é…ç½®ä»¥è·å–æ›´å¤šæ–‡ç« 
        from src.core.config import Config
        original_hours = Config.FETCH_ARTICLES_HOURS
        Config.FETCH_ARTICLES_HOURS = 24  # ä¸´æ—¶è®¾ç½®ä¸º24å°æ—¶
        
        items = rss_fetcher.fetch_latest_items(since_minutes=1440, enable_dedup=False)  # è·å–æœ€è¿‘24å°æ—¶çš„æ–‡ç« ï¼Œç¦ç”¨å»é‡
        
        # æ¢å¤åŸé…ç½®
        Config.FETCH_ARTICLES_HOURS = original_hours
        
        print(f"è·å–åˆ° {len(items)} ç¯‡æ–‡ç« ")
        
        # ç»Ÿè®¡å›¾ç‰‡ä¿¡æ¯
        total_images = 0
        downloaded_images = 0
        
        for i, item in enumerate(items[:5]):  # åªæ˜¾ç¤ºå‰5ç¯‡
            print(f"\nğŸ“„ æ–‡ç«  {i+1}: {item.title[:50]}...")
            print(f"   å‘å¸ƒæ—¶é—´: {item.published}")
            print(f"   é“¾æ¥: {item.link}")
            
            if item.has_image():
                total_images += 1
                print(f"   ğŸ“¸ å›¾ç‰‡URL: {item.image_url}")
                
                if item.has_local_image():
                    downloaded_images += 1
                    print(f"   ğŸ’¾ æœ¬åœ°è·¯å¾„: {item.local_image_path}")
                    
                    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦çœŸå®å­˜åœ¨
                    if os.path.exists(item.local_image_path):
                        file_size = os.path.getsize(item.local_image_path)
                        print(f"   ğŸ“Š æ–‡ä»¶å¤§å°: {file_size} bytes")
                    else:
                        print("   âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨!")
                else:
                    print("   âŒ å›¾ç‰‡ä¸‹è½½å¤±è´¥")
            else:
                print("   ğŸ“· æ— å›¾ç‰‡")
        
        print("\nğŸ“Š å›¾ç‰‡ç»Ÿè®¡:")
        print(f"   æ€»æ–‡ç« æ•°: {len(items)}")
        print(f"   æœ‰å›¾ç‰‡æ–‡ç« : {total_images}")
        print(f"   ä¸‹è½½æˆåŠŸ: {downloaded_images}")
        print(f"   ä¸‹è½½æˆåŠŸç‡: {(downloaded_images/total_images*100) if total_images > 0 else 0:.1f}%")
        
        # æ˜¾ç¤ºå›¾ç‰‡ç›®å½•ä¿¡æ¯
        images_dir = "images"
        if os.path.exists(images_dir):
            image_files = [f for f in os.listdir(images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp'))]
            total_size = sum(os.path.getsize(os.path.join(images_dir, f)) for f in image_files)
            
            print("\nğŸ“ å›¾ç‰‡ç›®å½•ä¿¡æ¯:")
            print(f"   ç›®å½•: {os.path.abspath(images_dir)}")
            print(f"   å›¾ç‰‡æ–‡ä»¶æ•°: {len(image_files)}")
            print(f"   æ€»å¤§å°: {total_size / 1024 / 1024:.2f} MB")
            
            if image_files:
                print(f"   æœ€æ–°æ–‡ä»¶: {image_files[-1]}")
        
        return True
        
    except Exception as e:
        print(f"âŒ RSSå›¾ç‰‡æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_image_cleanup():
    """æµ‹è¯•å›¾ç‰‡æ¸…ç†åŠŸèƒ½"""
    print("\nğŸ§¹ æµ‹è¯•å›¾ç‰‡æ¸…ç†åŠŸèƒ½...")
    
    try:
        rss_fetcher = RSSFetcher()
        deleted_count = rss_fetcher.cleanup_old_images(days=0)  # æ¸…ç†æ‰€æœ‰å›¾ç‰‡ï¼ˆæµ‹è¯•ç”¨ï¼‰
        print(f"æ¸…ç†äº† {deleted_count} ä¸ªå›¾ç‰‡æ–‡ä»¶")
        return True
    except Exception as e:
        print(f"âŒ å›¾ç‰‡æ¸…ç†æµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    try:
        success1 = test_image_download()
        success2 = test_image_cleanup()
        
        if success1 and success2:
            print("\nğŸ‰ RSSå›¾ç‰‡ä¸‹è½½åŠŸèƒ½æµ‹è¯•å®Œæˆï¼")
            print("\nğŸ’¡ åŠŸèƒ½ç‰¹æ€§:")
            print("   âœ… è‡ªåŠ¨ä»RSSæ¡ç›®ä¸­æå–å›¾ç‰‡URL")
            print("   âœ… æ”¯æŒå¤šç§å›¾ç‰‡æ ¼å¼ï¼ˆjpg, png, gif, webpç­‰ï¼‰")
            print("   âœ… è‡ªåŠ¨ä¸‹è½½å¹¶ä¿å­˜åˆ°æœ¬åœ°")
            print("   âœ… å›¾ç‰‡ä¸æ–‡ç« å…³è”ï¼Œæ”¯æŒå‘é€æ—¶ä½¿ç”¨")
            print("   âœ… æ”¯æŒä»£ç†ä¸‹è½½")
            print("   âœ… æ–‡ä»¶å¤§å°é™åˆ¶å’Œå®‰å…¨æ£€æŸ¥")
            print("   âœ… æ—§å›¾ç‰‡è‡ªåŠ¨æ¸…ç†åŠŸèƒ½")
        else:
            print("\nğŸ’¥ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
