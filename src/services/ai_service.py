"""
AIæ€»ç»“æ¨¡å—
"""
import re
import logging
from typing import List, Optional
from openai import OpenAI
import time
from bs4 import BeautifulSoup
import subprocess
import tempfile
import os

from ..core.config import Config
from ..core.prompts import PromptTemplates
from ..core.utils import setup_logger
from .rss_service import RSSItem

logger = setup_logger(__name__)


class Summarizer:
    """AIæ€»ç»“å™¨"""

    def __init__(self):
        if not Config.OPENAI_API_KEY:
            raise ValueError("éœ€è¦é…ç½®OPENAI_API_KEY")

        # åŸºç¡€é…ç½®
        client_kwargs = {
            "api_key": Config.OPENAI_API_KEY,
            "base_url": Config.OPENAI_BASE_URL
        }
        
        # å°è¯•æ·»åŠ ä»£ç†é…ç½®
        try:
            proxies = Config.get_proxies() if hasattr(Config, 'get_proxies') else None
            if proxies:
                import httpx
                # ä½¿ç”¨æ–°ç‰ˆæœ¬çš„httpxä»£ç†é…ç½®
                proxy_url = proxies.get('https') or proxies.get('http')
                if proxy_url:
                    client_kwargs["http_client"] = httpx.Client(proxy=proxy_url)
                    logger.info(f"Summarizerä½¿ç”¨ä»£ç†: {proxy_url}")
        except Exception as e:
            logger.warning(f"ä»£ç†é…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è¿æ¥: {e}")
        
        try:
            self.client = OpenAI(**client_kwargs)
            logger.info("OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            # å¦‚æœä»£ç†é…ç½®æœ‰é—®é¢˜ï¼Œå°è¯•ä¸ä½¿ç”¨ä»£ç†
            logger.info("å°è¯•ä¸ä½¿ç”¨ä»£ç†é‡æ–°åˆå§‹åŒ–...")
            client_kwargs_no_proxy = {
                "api_key": Config.OPENAI_API_KEY,
                "base_url": Config.OPENAI_BASE_URL
            }
            try:
                self.client = OpenAI(**client_kwargs_no_proxy)
                logger.info("OpenAIå®¢æˆ·ç«¯å·²ä½¿ç”¨é»˜è®¤è¿æ¥åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e2:
                logger.error(f"æ— ä»£ç†åˆå§‹åŒ–ä¹Ÿå¤±è´¥: {e2}")
                raise


    def clean_html(self, text: str) -> str:
        """æ¸…ç†HTMLæ ‡ç­¾"""
        if not text:
            return ""

        # ä½¿ç”¨BeautifulSoupæ¸…ç†HTML
        soup = BeautifulSoup(text, "html.parser")
        cleaned = soup.get_text()

        # æ¸…ç†å¤šä½™çš„ç©ºç™½å­—ç¬¦
        cleaned = re.sub(r"\s+", " ", cleaned).strip()
        return cleaned

    def clean_content_for_wechat(self, content: str) -> str:
        """ä¸“é—¨ä¸ºå¾®ä¿¡å…¬ä¼—å·æ¸…ç†å†…å®¹æ ¼å¼"""
        if not content:
            return ""
        
        # 1. æ¸…ç†ä¸éœ€è¦çš„æ ‡é¢˜å‰ç¼€ï¼ˆä¿ç•™åŸå§‹ç»“æ„ï¼‰
        prefixes_to_remove = [
            r'ğŸ“°\s*\*\*ä¼˜åŒ–æ ‡é¢˜\*\*:\s*',
            r'ä¼˜åŒ–æ ‡é¢˜:\s*',
            r'ğŸ“°\s*\*\*æ ‡é¢˜\*\*:\s*',
            r'æ ‡é¢˜:\s*',
        ]
        
        for prefix in prefixes_to_remove:
            content = re.sub(prefix, '', content, flags=re.IGNORECASE)
        
        # 2. é€‚åº¦æ¸…ç†ç©ºç™½å­—ç¬¦ï¼Œä¿ç•™æ®µè½ç»“æ„
        content = re.sub(r'\n\s*\n\s*\n+', '\n\n', content)  # å¤šä¸ªè¿ç»­ç©ºè¡Œåˆå¹¶ä¸ºä¸¤ä¸ª
        content = re.sub(r'[ \t]+', ' ', content)  # å¤šä¸ªç©ºæ ¼åˆå¹¶ä¸ºä¸€ä¸ª
        content = re.sub(r'^\s+', '', content, flags=re.MULTILINE)  # å»é™¤è¡Œé¦–ç©ºæ ¼
        content = re.sub(r'\s+$', '', content, flags=re.MULTILINE)  # å»é™¤è¡Œå°¾ç©ºæ ¼
        
        # 3. æ¸…ç†HTMLä¸­çš„å¤šä½™ç©ºæ ¼ï¼ˆå¦‚æœå·²ç»æ˜¯HTMLï¼‰
        if '<' in content and '>' in content:
            content = re.sub(r'>\s+<', '><', content)  # å»é™¤æ ‡ç­¾é—´ç©ºæ ¼
            content = re.sub(r'<p>\s*</p>', '', content)  # ç§»é™¤ç©ºæ®µè½
            content = re.sub(r'<div>\s*</div>', '', content)  # ç§»é™¤ç©ºdiv
        
        return content.strip()

    def markdown_to_html(self, text: str) -> str:
        """å°†Markdownæ ¼å¼è½¬æ¢ä¸ºHTMLæ ¼å¼ï¼Œä½¿ç”¨pandocè¿›è¡Œè½¬æ¢å¹¶æ¸…ç†ç©ºæ ¼"""
        if not text:
            return ""
        
        try:
            # å…ˆè¿›è¡ŒåŸºæœ¬æ¸…ç†
            text = self.clean_content_for_wechat(text)
            
            # ä½¿ç”¨pandocè¿›è¡Œè½¬æ¢
            try:
                import pypandoc
                # å°†markdownè½¬æ¢ä¸ºHTML
                html_content = pypandoc.convert_text(
                    text, 
                    'html', 
                    format='md',
                    extra_args=[
                        '--no-highlight',  # ç¦ç”¨ä»£ç é«˜äº®
                        '--wrap=none',     # ä¸è‡ªåŠ¨æ¢è¡Œ
                        '--email-obfuscation=none'  # ä¸æ··æ·†é‚®ç®±
                    ]
                )
                
                # è¿›ä¸€æ­¥æ¸…ç†HTML
                html_content = self.clean_content_for_wechat(html_content)
                
                return html_content
                
            except ImportError:
                logger.warning("pypandocæœªå®‰è£…ï¼Œä½¿ç”¨ç®€å•è½¬æ¢")
                return self._simple_markdown_to_html(text)
                
        except Exception as e:
            logger.error(f"Markdownè½¬HTMLå¤±è´¥: {e}")
            return self._simple_markdown_to_html(text)
    
    def _simple_markdown_to_html(self, text: str) -> str:
        """ç®€å•çš„Markdownåˆ°HTMLè½¬æ¢ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        if not text:
            return ""
        
        # å…ˆè¿›è¡ŒåŸºæœ¬æ¸…ç†
        text = self.clean_content_for_wechat(text)
        
        # è½¬æ¢æ ‡é¢˜ï¼ˆåœ¨è½¬æ¢å…¶ä»–å†…å®¹ä¹‹å‰ï¼‰
        text = re.sub(r'^### (.*?)$', r'<h3>\1</h3>', text, flags=re.MULTILINE)
        text = re.sub(r'^## (.*?)$', r'<h2>\1</h2>', text, flags=re.MULTILINE)
        text = re.sub(r'^# (.*?)$', r'<h1>\1</h1>', text, flags=re.MULTILINE)
        
        # è½¬æ¢åˆ—è¡¨é¡¹ï¼ˆå…ˆæ”¶é›†æ‰€æœ‰åˆ—è¡¨é¡¹ï¼‰
        lines = text.split('\n')
        processed_lines = []
        in_list = False
        
        for line in lines:
            line_stripped = line.strip()
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯åˆ—è¡¨é¡¹
            if re.match(r'^[-\*\+]\s+', line_stripped):
                if not in_list:
                    processed_lines.append('<ul>')
                    in_list = True
                # è½¬æ¢åˆ—è¡¨é¡¹
                list_content = re.sub(r'^[-\*\+]\s+', '', line_stripped)
                processed_lines.append(f'<li>{list_content}</li>')
            else:
                if in_list:
                    processed_lines.append('</ul>')
                    in_list = False
                processed_lines.append(line)
        
        # å¦‚æœæ–‡æ¡£ç»“æŸæ—¶è¿˜åœ¨åˆ—è¡¨ä¸­ï¼Œå…³é—­åˆ—è¡¨
        if in_list:
            processed_lines.append('</ul>')
        
        text = '\n'.join(processed_lines)
        
        # è½¬æ¢ç²—ä½“å’Œæ–œä½“
        text = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', text)
        text = re.sub(r'\*(.*?)\*', r'<em>\1</em>', text)
        
        # è½¬æ¢é“¾æ¥ [text](url) -> <a href="url">text</a>
        text = re.sub(r'\[([^\]]+)\]\(([^)]+)\)', r'<a href="\2">\1</a>', text)
        
        # å¤„ç†æ®µè½ï¼ˆé¿å…æŠŠå·²æœ‰çš„HTMLæ ‡ç­¾åŒ…è£…åœ¨pæ ‡ç­¾ä¸­ï¼‰
        paragraphs = text.split('\n\n')
        html_paragraphs = []
        
        for p in paragraphs:
            p = p.strip()
            if p:
                # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯HTMLæ ‡ç­¾ï¼ˆæ ‡é¢˜ã€åˆ—è¡¨ç­‰ï¼‰
                if re.match(r'<(h[1-6]|ul|ol|li)', p) or p.startswith('<'):
                    html_paragraphs.append(p)
                else:
                    # æ™®é€šæ–‡æœ¬åŒ…è£…åœ¨pæ ‡ç­¾ä¸­
                    html_paragraphs.append(f'<p>{p}</p>')
        
        result = '\n\n'.join(html_paragraphs)
        
        # æœ€åæ¸…ç†
        return result

    def _extract_article_metadata(self, content: str) -> tuple[str, dict]:
        """ä»AIç”Ÿæˆçš„å†…å®¹ä¸­æå–è¯„åˆ†å’Œæ ‡ç­¾ç­‰å…ƒæ•°æ®"""
        metadata = {}
        
        # æŸ¥æ‰¾è¯„åˆ†ä¿¡æ¯
        score_pattern = r'ğŸ“Š\s*çƒ­åº¦è¯„åˆ†[ï¼š:]\s*(\d+(?:\.\d+)?)'
        score_match = re.search(score_pattern, content)
        if score_match:
            metadata['score'] = float(score_match.group(1))
        
        # æŸ¥æ‰¾ç›®æ ‡å—ä¼—
        audience_pattern = r'ğŸ¯\s*ç›®æ ‡å—ä¼—[ï¼š:]\s*([^\n]+)'
        audience_match = re.search(audience_pattern, content)
        if audience_match:
            metadata['audience'] = audience_match.group(1).strip()
        
        # æŸ¥æ‰¾æ ‡ç­¾
        tags_pattern = r'ğŸ·ï¸\s*æ–‡ç« æ ‡ç­¾[ï¼š:]\s*([^\n]+)'
        tags_match = re.search(tags_pattern, content)
        if tags_match:
            tags_text = tags_match.group(1).strip()
            # æå–æ‰€æœ‰æ ‡ç­¾ï¼Œå»é™¤HTMLæ ‡ç­¾
            tags_text = re.sub(r'<[^>]+>', '', tags_text)  # æ¸…ç†HTMLæ ‡ç­¾
            tag_matches = re.findall(r'#([^#\s<>]+)', tags_text)
            metadata['tags'] = tag_matches
        
        # ç§»é™¤å…ƒæ•°æ®éƒ¨åˆ†ï¼Œåªä¿ç•™ä¸»è¦å†…å®¹
        # æŸ¥æ‰¾å…ƒæ•°æ®å¼€å§‹çš„ä½ç½®ï¼ˆé€šå¸¸åœ¨æœ€åï¼‰
        metadata_start = content.find('ğŸ“Š çƒ­åº¦è¯„åˆ†')
        if metadata_start == -1:
            metadata_start = content.find('**ğŸ“Š çƒ­åº¦è¯„åˆ†')
        
        if metadata_start != -1:
            clean_content = content[:metadata_start].strip()
        else:
            clean_content = content
        
        return clean_content, metadata

    def get_article_engagement_score(self, content: str) -> float:
        """è·å–æ–‡ç« çš„å‚ä¸åº¦è¯„åˆ†"""
        try:
            _, metadata = self._extract_article_metadata(content)
            return metadata.get('score', 5.0)  # é»˜è®¤è¯„åˆ†5.0
        except:
            return 5.0

    def get_article_tags(self, content: str) -> list:
        """è·å–æ–‡ç« æ ‡ç­¾"""
        try:
            _, metadata = self._extract_article_metadata(content)
            return metadata.get('tags', [])
        except:
            return []

    def summarize_single_item(self, item: RSSItem, sender_type: str = "wechat") -> str:
        """
        ä¸ºå•ç¯‡æ–‡ç« ç”Ÿæˆä¸“é—¨çš„AIæ€»ç»“

        Args:
            item: å•ä¸ªRSSæ¡ç›®
            sender_type: å‘é€æºç±»å‹ ("wechat", "wechat_official", "xiaohongshu")

        Returns:
            é’ˆå¯¹è¯¥æ–‡ç« çš„ä¸“é—¨æ€»ç»“å†…å®¹
        """
        if not item:
            return ""

        try:
            # æ¸…ç†æ–‡ç« å†…å®¹
            clean_title = item.title.strip()
            clean_desc = self.clean_html(item.description)

            # æ ¹æ®å‘é€æºé€‰æ‹©ä¸åŒçš„æç¤ºè¯æ¨¡æ¿
            if sender_type in ["wechat_official", "xiaohongshu"]:
                # å…¬ä¼—å·å’Œå°çº¢ä¹¦ä¸é™åˆ¶å­—æ•°
                prompt = PromptTemplates.get_single_article_prompt(
                    title=clean_title,
                    content=clean_desc[:1000],  # å¢åŠ å†…å®¹é•¿åº¦ç”¨äºæ·±åº¦åˆ†æ
                    link=item.link,
                    min_length=0,  # ä¸é™åˆ¶æœ€å°é•¿åº¦
                    max_length=0,  # ä¸é™åˆ¶æœ€å¤§é•¿åº¦
                    sender_type=sender_type,
                )
                max_tokens = 2000  # å¢åŠ tokené™åˆ¶
            else:
                # å¾®ä¿¡ä¸ªäººå·ä¿æŒåŸæœ‰é™åˆ¶
                prompt = PromptTemplates.get_single_article_prompt(
                    title=clean_title,
                    content=clean_desc[:500],  # é™åˆ¶å†…å®¹é•¿åº¦é¿å…tokenè¶…é™
                    link=item.link,
                    min_length=Config.SUMMARY_MIN_LENGTH,
                    max_length=Config.SUMMARY_MAX_LENGTH,
                    sender_type=sender_type,
                )
                max_tokens = 800

            # è°ƒç”¨AI APIï¼Œä½¿ç”¨å‘é€æºå¯¹åº”çš„ç³»ç»Ÿè§’è‰²
            response = self.client.chat.completions.create(
                model="deepseek-chat",  # ä½¿ç”¨DeepSeekæ¨¡å‹
                messages=[
                    {
                        "role": "system",
                        "content": PromptTemplates.get_system_role(
                            "content_strategist", sender_type
                        ),
                    },
                    {"role": "user", "content": prompt},
                ],
                max_tokens=max_tokens,
                temperature=0.8,
            )

            summary = response.choices[0].message.content.strip()

            # è§£æå’Œå¤„ç†è¯„åˆ†æ ‡ç­¾ä¿¡æ¯ï¼ˆä»…å¯¹å¾®ä¿¡å…¬ä¼—å·ï¼‰
            if sender_type == "wechat_official":
                summary, metadata = self._extract_article_metadata(summary)
                
                # è®°å½•è¯„åˆ†å’Œæ ‡ç­¾ä¿¡æ¯
                if metadata:
                    logger.info(f"æ–‡ç« å…ƒæ•°æ® - çƒ­åº¦è¯„åˆ†: {metadata.get('score', 'N/A')}, "
                              f"ç›®æ ‡å—ä¼—: {metadata.get('audience', 'N/A')}, "
                              f"æ ‡ç­¾: {metadata.get('tags', 'N/A')}")
                
                if "å»¶ä¼¸é˜…è¯»" not in summary and "åŸæ–‡é“¾æ¥" not in summary and item.link not in summary:
                    summary += f"\n\nğŸ”— **å»¶ä¼¸é˜…è¯»**ï¼š[æŸ¥çœ‹å®Œæ•´æŠ€æœ¯è¯¦æƒ…]({item.link})"
                # å¯¹å¾®ä¿¡å…¬ä¼—å·å†…å®¹è¿›è¡ŒMarkdownåˆ°HTMLè½¬æ¢
                summary = self.markdown_to_html(summary)
            elif sender_type == "xiaohongshu":
                if "äº†è§£æ›´å¤š" not in summary and "åŸæ–‡" not in summary and item.link not in summary:
                    summary += f"\n\nğŸ“– æƒ³äº†è§£æ›´å¤šæŠ€æœ¯ç»†èŠ‚ï¼ŸğŸ‘†ç‚¹å‡»æŸ¥çœ‹åŸæ–‡å“¦~\n{item.link}"
            else:
                if "é˜…è¯»åŸæ–‡" not in summary and item.link not in summary:
                    summary += f"\n\nğŸ“– é˜…è¯»åŸæ–‡ï¼š{item.link}"

            logger.info(f"å•ç¯‡æ–‡ç« AIæ€»ç»“å®Œæˆ ({sender_type}) - æ ‡é¢˜: {clean_title[:30]}..., å­—æ•°: {len(summary)}")
            return summary

        except Exception as e:
            logger.error(f"å•ç¯‡æ–‡ç« AIæ€»ç»“å¤±è´¥: {e}")
            # é™çº§åˆ°ç®€å•æ€»ç»“
            return self._simple_single_summary(item)

    def summarize_items(self, items: List[RSSItem], sender_type: str = "wechat") -> str:
        """
        ä¸ºå¤šä¸ªRSSæ¡ç›®ç”Ÿæˆæ€»ç»“ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
        ç°åœ¨æ”¹ä¸ºåˆ†åˆ«æ€»ç»“æ¯ç¯‡æ–‡ç« 

        Args:
            items: RSSæ¡ç›®åˆ—è¡¨
            sender_type: å‘é€æºç±»å‹

        Returns:
            æ€»ç»“åçš„å¾®ä¿¡æ¶ˆæ¯å†…å®¹
        """
        if not items:
            return ""

        # å¦‚æœåªæœ‰ä¸€ç¯‡æ–‡ç« ï¼Œç›´æ¥ä½¿ç”¨å•ç¯‡æ€»ç»“
        if len(items) == 1:
            return self.summarize_single_item(items[0], sender_type)

        # å¤šç¯‡æ–‡ç« æ—¶ï¼Œç”Ÿæˆç®€åŒ–çš„æ±‡æ€»
        try:
            summaries = []
            for item in items[:3]:  # æœ€å¤šå¤„ç†3ç¯‡
                summary = self.summarize_single_item(item)
                if summary:
                    summaries.append(f"ğŸ“° {item.title}\n{summary}")

            if summaries:
                return "\n\n" + "=" * 20 + "\n\n".join(summaries)
            else:
                return self._simple_summary(items)

        except Exception as e:
            logger.error(f"æ‰¹é‡æ–‡ç« æ€»ç»“å¤±è´¥: {e}")
            return self._simple_summary(items)

    def _simple_single_summary(self, item: RSSItem) -> str:
        """å•ç¯‡æ–‡ç« çš„ç®€å•æ€»ç»“æ–¹å¼ï¼ˆå½“AIå¤±è´¥æ—¶ä½¿ç”¨ï¼‰"""
        if not item:
            return ""

        # æ¸…ç†æ ‡é¢˜å’Œæè¿°
        clean_title = item.title.strip()
        clean_desc = self.clean_html(item.description)

        # ç”Ÿæˆç®€å•ä½†ç»“æ„åŒ–çš„æ€»ç»“
        summary = f"ğŸ“° {clean_title}\n\n"

        # æ·»åŠ æè¿°ï¼ˆæˆªæ–­åˆ°åˆé€‚é•¿åº¦ï¼‰
        if clean_desc:
            desc_limit = Config.SUMMARY_MAX_LENGTH - len(summary) - 100  # ä¸ºé“¾æ¥é¢„ç•™ç©ºé—´
            if len(clean_desc) > desc_limit:
                summary += f"ğŸ’¡ {clean_desc[:desc_limit]}...\n\n"
            else:
                summary += f"ğŸ’¡ {clean_desc}\n\n"

        # æ·»åŠ é“¾æ¥
        summary += f"ğŸ”— é˜…è¯»åŸæ–‡ï¼š{item.link}"

        return summary

    def _simple_summary(self, items: List[RSSItem]) -> str:
        """ç®€å•çš„æ€»ç»“æ–¹å¼ï¼ˆå½“AIå¤±è´¥æ—¶ä½¿ç”¨ï¼‰"""
        if not items:
            return ""

        summary = f"ğŸ“° æœ€æ–°èµ„è®¯ ({len(items)}æ¡)\n\n"

        for i, item in enumerate(items[:3], 1):
            summary += f"{i}. {item.title}\n"
            if len(summary) > Config.SUMMARY_MAX_LENGTH:
                summary = summary[: Config.SUMMARY_MAX_LENGTH - 10] + "..."
                break

        summary += "\nğŸ”— æŸ¥çœ‹è¯¦æƒ…ï¼š"
        for i, item in enumerate(items[:3], 1):
            return summary

    def classify_article(self, item: RSSItem) -> str:
        """
        å¯¹æ–‡ç« è¿›è¡Œåˆ†ç±»

        Args:
            item: RSSæ¡ç›®

        Returns:
            æ–‡ç« åˆ†ç±»ï¼ˆTechnology, Development, Entertainment, Finance, Health, Politics, Otherï¼‰
        """
        if not item:
            return "Other"

        try:
            # å‡†å¤‡æ–‡ç« å†…å®¹
            content = f"Title: {item.title}\nContent: {self.clean_html(item.description)[:300]}"

            response = self.client.chat.completions.create(
                model="deepseek-chat",  # æ–‡ç« åˆ†ç±»ä½¿ç”¨DeepSeekæ¨¡å‹
                messages=[
                    {
                        "role": "system",
                        "content": PromptTemplates.get_system_role("content_analyst"),
                    },
                    {
                        "role": "user",
                        "content": f"{PromptTemplates.ARTICLE_CLASSIFICATION}\n\nContent:\n{content}",
                    },
                ],
                max_tokens=50,
                temperature=0.1,
            )

            category = response.choices[0].message.content.strip()
            logger.info(f"æ–‡ç« åˆ†ç±»å®Œæˆ: {item.title[:30]}... -> {category}")
            return category

        except Exception as e:
            logger.error(f"æ–‡ç« åˆ†ç±»å¤±è´¥: {e}")
            return "Other"

    def generate_tags(self, item: RSSItem) -> str:
        """
        ä¸ºæ–‡ç« ç”Ÿæˆæ ‡ç­¾

        Args:
            item: RSSæ¡ç›®

        Returns:
            æ–‡ç« æ ‡ç­¾ï¼ˆé€—å·åˆ†éš”ï¼‰
        """
        if not item:
            return ""

        try:
            # å‡†å¤‡æ–‡ç« å†…å®¹
            content = f"Title: {item.title}\nContent: {self.clean_html(item.description)[:300]}"

            response = self.client.chat.completions.create(
                model="deepseek-chat",  # æ ‡ç­¾ç”Ÿæˆä½¿ç”¨DeepSeekæ¨¡å‹
                messages=[
                    {
                        "role": "system",
                        "content": PromptTemplates.get_system_role("content_analyst"),
                    },
                    {
                        "role": "user",
                        "content": f"{PromptTemplates.ARTICLE_TAGS}\n\nContent:\n{content}",
                    },
                ],
                max_tokens=100,
                temperature=0.3,
            )

            tags = response.choices[0].message.content.strip()
            logger.info(f"æ ‡ç­¾ç”Ÿæˆå®Œæˆ: {item.title[:30]}... -> {tags}")
            return tags

        except Exception as e:
            logger.error(f"æ ‡ç­¾ç”Ÿæˆå¤±è´¥: {e}")
            return ""

    def score_article(self, item: RSSItem) -> int:
        """
        ä¸ºæ–‡ç« è¯„åˆ†

        Args:
            item: RSSæ¡ç›®

        Returns:
            æ–‡ç« è¯„åˆ†ï¼ˆ0-10ï¼‰
        """
        if not item:
            return 0

        try:
            # å‡†å¤‡æ–‡ç« å†…å®¹
            content = f"Title: {item.title}\nContent: {self.clean_html(item.description)[:500]}"

            response = self.client.chat.completions.create(
                model="deepseek-chat",  # æ–‡ç« è¯„åˆ†ä½¿ç”¨DeepSeekæ¨¡å‹
                messages=[
                    {
                        "role": "system",
                        "content": PromptTemplates.get_system_role("content_analyst"),
                    },
                    {
                        "role": "user",
                        "content": f"{PromptTemplates.ARTICLE_SCORING}\n\nContent:\n{content}",
                    },
                ],
                max_tokens=20,
                temperature=0.1,
            )

            score_text = response.choices[0].message.content.strip()
            try:
                score = int(score_text)
                score = max(0, min(10, score))  # ç¡®ä¿åˆ†æ•°åœ¨0-10èŒƒå›´å†…
            except ValueError:
                score = 5  # é»˜è®¤åˆ†æ•°

            logger.info(f"æ–‡ç« è¯„åˆ†å®Œæˆ: {item.title[:30]}... -> {score}")
            return score

        except Exception as e:
            logger.error(f"æ–‡ç« è¯„åˆ†å¤±è´¥: {e}")
            # åŸºäºç®€å•è§„åˆ™çš„é™çº§è¯„åˆ†
            return self._simple_score_article(item)

    def _simple_score_article(self, item: RSSItem) -> int:
        """
        ç®€å•çš„æ–‡ç« è¯„åˆ†æ–¹æ³•ï¼ˆå½“AIå¤±è´¥æ—¶ä½¿ç”¨ï¼‰
        åŸºäºæ ‡é¢˜é•¿åº¦ã€æè¿°é•¿åº¦å’Œå…³é”®è¯æ¥è¯„åˆ†
        """
        score = 5  # åŸºç¡€åˆ†æ•°

        try:
            # æ ‡é¢˜è´¨é‡è¯„åˆ†
            title_len = len(item.title.strip())
            if title_len > 10:
                score += 1
            if title_len > 20:
                score += 1

            # æè¿°è´¨é‡è¯„åˆ†
            desc_len = len(self.clean_html(item.description))
            if desc_len > 100:
                score += 1
            if desc_len > 300:
                score += 1

            # å…³é”®è¯åŠ åˆ†
            quality_keywords = [
                "è·å¥–",
                "çªç ´",
                "åˆ›æ–°",
                "å‘å¸ƒ",
                "å®£å¸ƒ",
                "åˆä½œ",
                "æŠ•èµ„",
                "èèµ„",
                "ä¸Šå¸‚",
                "æ”¶è´­",
            ]
            content_text = (item.title + " " + item.description).lower()
            for keyword in quality_keywords:
                if keyword in content_text:
                    score += 0.5
                    break

            score = max(0, min(10, int(score)))
            logger.info(f"ç®€å•è¯„åˆ†å®Œæˆ: {item.title[:30]}... -> {score}")
            return score

        except Exception as e:
            logger.error(f"ç®€å•è¯„åˆ†ä¹Ÿå¤±è´¥: {e}")
            return 5

    def _extract_quality_info(self, response_text: str) -> dict:
        """ä»AIå“åº”ä¸­æå–è´¨é‡ä¿¡æ¯
        
        Args:
            response_text: AIå“åº”æ–‡æœ¬
            
        Returns:
            åŒ…å«quality_score, summary, reasoningç­‰å­—æ®µçš„å­—å…¸
        """
        try:
            import json
            # å°è¯•è§£æJSONæ ¼å¼çš„å“åº”
            data = json.loads(response_text.strip())
            return {
                'quality_score': data.get('quality_score', 5),
                'summary': data.get('summary', ''),
                'reasoning': data.get('reasoning', ''),
                'key_points': data.get('key_points', [])
            }
        except (json.JSONDecodeError, ValueError):
            # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–åˆ†æ•°
            import re
            score_match = re.search(r'(?:quality_score|è¯„åˆ†|åˆ†æ•°).*?(\d+)', response_text, re.IGNORECASE)
            score = int(score_match.group(1)) if score_match else 5
            
            return {
                'quality_score': min(10, max(0, score)),
                'summary': response_text[:200] if len(response_text) > 200 else response_text,
                'reasoning': 'æ— æ³•è§£æè¯¦ç»†è¯„åˆ†ä¿¡æ¯',
                'key_points': []
            }
